{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H1\n",
    "## H2\n",
    "### H3\n",
    "#### H4\n",
    "##### H5\n",
    "###### H6\n",
    "\n",
    "Alternatively, for H1 and H2, an underline-ish style:\n",
    "\n",
    "Alt-H1\n",
    "======\n",
    "\n",
    "Alt-H2\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emphasis, aka italics, with *asterisks* or _underscores_.\n",
    "\n",
    "~~fuck~~\n",
    "\n",
    "Strong emphasis, aka bold, with **asterisks** or __underscores__.\n",
    "\n",
    "Combined emphasis with **asterisks and _underscores_**.\n",
    "\n",
    "Strikethrough uses two tildes. ~~Scratch this.~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First ordered list item\n",
    "2. Another item\n",
    "⋅⋅* Unordered sub-list. \n",
    "1. Actual numbers don't matter, just that it's a number\n",
    "⋅⋅1. Ordered sub-list\n",
    "4. And another item.\n",
    "\n",
    "⋅⋅⋅You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we'll use three here to also align the raw Markdown).\n",
    "\n",
    "⋅⋅⋅To have a line break without a paragraph, you will need to use two trailing spaces.⋅⋅\n",
    "⋅⋅⋅Note that this line is separate, but within the same paragraph.⋅⋅\n",
    "⋅⋅⋅(This is contrary to the typical GFM line break behaviour, where trailing spaces are not required.)\n",
    "\n",
    "* Unordered list can use asterisks\n",
    "- Or minuses\n",
    "+ Or pluses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "s = \"Python syntax highlighting\"\n",
    "print s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Philosophy of Bayesian Inference\n",
    "------\n",
    "  \n",
    "> You are a skilled programmer, but bugs still slip into your code. After a particularly difficult implementation of an algorithm, you decide to test your code on a trivial example. It passes. You test the code on a harder problem. It passes once again. And it passes the next, *even more difficult*, test too! You are starting to believe that there may be no bugs in this code...\n",
    "\n",
    "If you think this way, then congratulations, you already are thinking Bayesian! Bayesian inference is simply updating your beliefs after considering new evidence. A Bayesian can rarely be certain about a result, but he or she can be very confident. Just like in the example above, we can never be 100% sure that our code is bug-free unless we test it on every possible problem; something rarely possible in practice. Instead, we can test it on a large number of problems, and if it succeeds we can feel more *confident* about our code, but still not certain.  Bayesian inference works identically: we update our beliefs about an outcome; rarely can we be absolutely sure unless we rule out all other alternatives. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
